{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31adb03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Standardized sanitation data: derived_data/sanitation_type_with_population.csv (279934 rows)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the original CSV\n",
    "df = pd.read_csv(\"input_data/sanitation_type.csv\")\n",
    "\n",
    "# Define the mapping\n",
    "column_mapping = {\n",
    "    \"fid\": \"id\",\n",
    "    \"Latitude\": \"lat\",\n",
    "    \"Longitude\": \"long\",\n",
    "    \"Toilets wi\": \"toilet_type_name\",\n",
    "    \"Type\": \"toilet_type_id\",\n",
    "    \"Descpt\": \"toilet_category_name\",\n",
    "    \"Category\": \"toilet_category_id\",\n",
    "    \"Region_Nam\": \"region_name\",\n",
    "    \"Dist_Nam\": \"district_name\",\n",
    "    \"Ward_Nam\": \"ward_name\",\n",
    "    \"Village_Na\": \"village_name\"\n",
    "}\n",
    "\n",
    "# Select and rename only the mapped columns\n",
    "df_mapped = df[list(column_mapping.keys())].rename(columns=column_mapping)\n",
    "\n",
    "# Save to new CSV\n",
    "df_mapped.to_csv(\"derived_data/sanitation_type_with_population.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "529fb688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- 1) Configuration object (list of dicts with name + id + efficiency) ---\n",
    "TOILET_CATEGORY_CONFIG = [\n",
    "    {\"name\": \"Septic Tank - 80\",      \"id\": 1, \"efficiency\": 0.8},\n",
    "    {\"name\": \"Pit Latrine - 20\",      \"id\": 2, \"efficiency\": 0.2},\n",
    "    {\"name\": \"Septic Tank sewer - 90\",\"id\": 3, \"efficiency\": 0.9},\n",
    "    {\"name\": \"Open defecation - 0\",   \"id\": 4, \"efficiency\": 0.0},\n",
    "]\n",
    "\n",
    "# Build a lookup dict (id → efficiency)\n",
    "EFF_BY_ID = {item[\"id\"]: item[\"efficiency\"] for item in TOILET_CATEGORY_CONFIG}\n",
    "\n",
    "# --- 2) Load data ---\n",
    "path = \"derived_data/sanitation_type_with_population.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Ensure toilet_category_id is numeric\n",
    "df[\"toilet_category_id\"] = pd.to_numeric(df[\"toilet_category_id\"], errors=\"coerce\")\n",
    "\n",
    "# --- 3) Map efficiency to new column ---\n",
    "df[\"pathogen_containment_efficiency\"] = df[\"toilet_category_id\"].map(EFF_BY_ID)\n",
    "\n",
    "\n",
    "# --- 4) Add household population (assumed uniform = 10 people) ---\n",
    "df[\"household_population\"] = 10\n",
    "\n",
    "# --- 5) Save and preview ---\n",
    "df.to_csv(path, index=False)  # overwrite same file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8fa2efa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "src = \"derived_data/sanitation_type_with_population.csv\"\n",
    "dst = \"derived_data/net_pathogen_load_from_households.csv\"\n",
    "os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "\n",
    "# EFIO_DEFAULT: Based on human feces ~128 g/day × ~10⁸ CFU/g → ~1.28×10¹⁰ CFU/person/day\n",
    "EFIO_DEFAULT = 1.28e10  # shedding rate used for L = Pop × EFIO × (1 – η)\n",
    "\n",
    "df = pd.read_csv(src)\n",
    "\n",
    "df[\"household_population\"] = pd.to_numeric(df[\"household_population\"], errors=\"coerce\").fillna(0)\n",
    "df[\"pathogen_containment_efficiency\"] = pd.to_numeric(\n",
    "    df.get(\"pathogen_containment_efficiency\", 0), errors=\"coerce\"\n",
    ").fillna(0)\n",
    "\n",
    "# Compute η and net load (L)\n",
    "df[\"fio_load\"] = df[\"household_population\"] * EFIO_DEFAULT * (1 - df[\"pathogen_containment_efficiency\"])\n",
    "\n",
    "df.to_csv(dst, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f67e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Input paths\n",
    "priv_src = \"input_data/private_boreholes.csv\"\n",
    "gov_src  = \"input_data/government_boreholes.csv\"\n",
    "\n",
    "# Output paths (new files, originals remain unchanged)\n",
    "priv_out = \"derived_data/private_boreholes_with_id.csv\"\n",
    "gov_out  = \"derived_data/government_boreholes_with_id.csv\"\n",
    "os.makedirs(\"derived_data\", exist_ok=True)\n",
    "\n",
    "def add_ids_copy(path_in, path_out, prefix):\n",
    "    df = pd.read_csv(path_in)\n",
    "\n",
    "    # Add id if missing, else move it to first column\n",
    "    if \"id\" not in df.columns:\n",
    "        df.insert(0, \"id\", [f\"{prefix}_{i+1}\" for i in range(len(df))])\n",
    "    else:\n",
    "        id_col = df.pop(\"id\")\n",
    "        df.insert(0, \"id\", id_col)\n",
    "\n",
    "    df.to_csv(path_out, index=False)\n",
    "    print(f\"✅ Saved {path_out} with {len(df)} rows (id column first)\")\n",
    "    return df\n",
    "\n",
    "# Generate new copies\n",
    "priv = add_ids_copy(priv_src, priv_out, \"privbh\")\n",
    "gov  = add_ids_copy(gov_src,  gov_out,  \"govbh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501b298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- Paths ----------\n",
    "toilets_src = \"derived_data/net_pathogen_load_from_households.csv\"   # must have id, lat, long, fio_load\n",
    "priv_src    = \"derived_data/private_boreholes_with_id.csv\"\n",
    "gov_src     = \"derived_data/government_boreholes_with_id.csv\"\n",
    "dst         = \"derived_data/net_surviving_pathogen_load_links.csv\"\n",
    "os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "\n",
    "# ---------- Config ----------\n",
    "KS_PER_M = 0.001  # m^-1 (decay constant, adjust per environment)\n",
    "\n",
    "RADIUS_BY_TYPE = {\n",
    "    \"private\": 30,      # cutoff radius for private boreholes (m)\n",
    "    \"government\": 100,   # cutoff radius for government boreholes (m)\n",
    "}\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def require_cols(df: pd.DataFrame, name: str, cols=(\"id\", \"lat\", \"long\")):\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{name}: missing required column(s): {missing}\")\n",
    "\n",
    "def haversine_m(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000.0\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat, dlon = lat2 - lat1, lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2\n",
    "    return 2*R*np.arcsin(np.minimum(1.0, np.sqrt(a)))\n",
    "\n",
    "def link_within_radius(toilets_df, bores_df, borehole_type: str, radius_m: float):\n",
    "    records = []\n",
    "    tgt_lat = bores_df[\"lat\"].to_numpy(float)\n",
    "    tgt_lon = bores_df[\"long\"].to_numpy(float)\n",
    "    tgt_id  = bores_df[\"id\"].to_numpy()\n",
    "\n",
    "    for _, row in toilets_df.iterrows():\n",
    "        d = haversine_m(row[\"lat\"], row[\"long\"], tgt_lat, tgt_lon)\n",
    "        mask = d <= radius_m\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "        contrib = row[\"fio_load\"] * np.exp(-KS_PER_M * d[mask])\n",
    "        for bid, dist, surv in zip(tgt_id[mask], d[mask], contrib):\n",
    "            records.append({\n",
    "                \"toilet_id\": row[\"id\"],\n",
    "                \"toilet_lat\": row[\"lat\"],\n",
    "                \"toilet_long\": row[\"long\"],\n",
    "                \"borehole_id\": bid,\n",
    "                \"borehole_type\": borehole_type,\n",
    "                \"distance_m\": float(dist),\n",
    "                \"surviving_fio_load\": float(surv),\n",
    "            })\n",
    "    return pd.DataFrame.from_records(records)\n",
    "\n",
    "# ---------- Load ----------\n",
    "toilets = pd.read_csv(toilets_src)\n",
    "priv    = pd.read_csv(priv_src)\n",
    "gov     = pd.read_csv(gov_src)\n",
    "\n",
    "require_cols(toilets, \"toilets\", (\"id\", \"lat\", \"long\", \"fio_load\"))\n",
    "require_cols(priv, \"private_boreholes\")\n",
    "require_cols(gov,  \"government_boreholes\")\n",
    "\n",
    "# ---------- Build link table ----------\n",
    "links_private = link_within_radius(toilets, priv, \"private\", RADIUS_BY_TYPE[\"private\"])\n",
    "links_government = link_within_radius(toilets, gov, \"government\", RADIUS_BY_TYPE[\"government\"])\n",
    "\n",
    "links = pd.concat([links_private, links_government], ignore_index=True)\n",
    "\n",
    "# ---------- Save + preview ----------\n",
    "links.to_csv(dst, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84de1684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- Paths ----------\n",
    "links_src = \"derived_data/net_surviving_pathogen_load_links.csv\"  # from Layer 2 (link table)\n",
    "priv_src  = \"derived_data/private_boreholes_with_id.csv\"          # has 'id' + coords (+ optional flow cols)\n",
    "gov_src   = \"derived_data/government_boreholes_with_id.csv\"\n",
    "links_out = \"derived_data/net_surviving_pathogen_concentration_links.csv\"\n",
    "bh_out    = \"derived_data/fio_concentration_at_boreholes.csv\"\n",
    "os.makedirs(os.path.dirname(links_out), exist_ok=True)\n",
    "\n",
    "# ---------- Config ----------\n",
    "# If borehole files have any of these columns, we'll compute Q (L/day) from them.\n",
    "# Priority order: first present/non-null wins.\n",
    "FLOW_COLUMN_PREFERENCE = [\n",
    "    # already in L/day\n",
    "    (\"Q_L_per_day\",          \"L_per_day\", 1.0),\n",
    "    (\"flow_L_per_day\",       \"L_per_day\", 1.0),\n",
    "\n",
    "    # in L/s -> convert to L/day (× 86400)\n",
    "    (\"discharge_Lps\",        \"L_per_s\",   86400.0),\n",
    "    (\"Q_Lps\",                \"L_per_s\",   86400.0),\n",
    "\n",
    "    # in m^3/day -> convert to L/day (× 1000)\n",
    "    (\"yield_m3_per_day\",     \"m3_per_day\", 1000.0),\n",
    "    (\"Q_m3_per_day\",         \"m3_per_day\", 1000.0),\n",
    "]\n",
    "\n",
    "# Type-specific default Q if not present in the files (units: L/day)\n",
    "Q_DEFAULT_BY_TYPE = {\n",
    "    \"private\":    2_000.0,   # example placeholder; adjust to your context\n",
    "    \"government\": 20_000.0,  # example placeholder; adjust to your context\n",
    "}\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def coerce_num(s):\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "def pick_Q_L_per_day(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Return a Series of Q (L/day) from the borehole dataframe:\n",
    "    - tries preferred columns (with unit conversions)\n",
    "    - returns NaN if nothing found\n",
    "    \"\"\"\n",
    "    q = pd.Series(np.nan, index=df.index, dtype=\"float64\")\n",
    "    for col, kind, factor in FLOW_COLUMN_PREFERENCE:\n",
    "        if col in df.columns:\n",
    "            vals = coerce_num(df[col])\n",
    "            q = q.fillna(vals * factor)  # only fill where q is NaN\n",
    "    return q\n",
    "\n",
    "def build_borehole_Q_map(df: pd.DataFrame, borehole_type: str) -> pd.DataFrame:\n",
    "    if \"id\" not in df.columns:\n",
    "        raise ValueError(f\"{borehole_type} boreholes: missing 'id' column.\")\n",
    "\n",
    "    q = pick_Q_L_per_day(df)\n",
    "    # fallback to default by type if Q still missing\n",
    "    q = q.fillna(Q_DEFAULT_BY_TYPE[borehole_type])\n",
    "\n",
    "    out = df[[\"id\"]].copy()\n",
    "    out[\"borehole_type\"] = borehole_type\n",
    "    out[\"Q_L_per_day\"] = coerce_num(q)\n",
    "    return out\n",
    "\n",
    "# ---------- Load ----------\n",
    "links = pd.read_csv(links_src)   # needs: borehole_id, borehole_type, surviving_fio_load\n",
    "priv  = pd.read_csv(priv_src)\n",
    "gov   = pd.read_csv(gov_src)\n",
    "\n",
    "required_link_cols = [\"borehole_id\", \"borehole_type\", \"surviving_fio_load\"]\n",
    "missing = [c for c in required_link_cols if c not in links.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"links file missing: {missing}\")\n",
    "\n",
    "# ---------- Build Q lookup ----------\n",
    "priv_q = build_borehole_Q_map(priv, \"private\")\n",
    "gov_q  = build_borehole_Q_map(gov,  \"government\")\n",
    "bh_q   = pd.concat([priv_q, gov_q], ignore_index=True)\n",
    "\n",
    "# ---------- Join Q and compute concentration per link ----------\n",
    "links[\"surviving_fio_load\"] = coerce_num(links[\"surviving_fio_load\"]).fillna(0)\n",
    "links = links.merge(bh_q.rename(columns={\"id\": \"borehole_id\"}), on=[\"borehole_id\", \"borehole_type\"], how=\"left\")\n",
    "\n",
    "if links[\"Q_L_per_day\"].isna().any():\n",
    "    # If any still NaN (e.g., borehole type label mismatch), raise to avoid silent errors\n",
    "    bad = links[links[\"Q_L_per_day\"].isna()][[\"borehole_id\", \"borehole_type\"]].drop_duplicates()\n",
    "    raise ValueError(f\"Missing Q for some boreholes:\\n{bad}\")\n",
    "\n",
    "# C = L_t / Q\n",
    "links[\"concentration_CFU_per_L\"] = links[\"surviving_fio_load\"] / links[\"Q_L_per_day\"]\n",
    "\n",
    "# ---------- Save link-level concentrations ----------\n",
    "links.to_csv(links_out, index=False)\n",
    "print(f\"✅ Wrote link-level concentrations: {links_out}\")\n",
    "print(links[[\"toilet_id\",\"borehole_id\",\"borehole_type\",\"surviving_fio_load\",\"Q_L_per_day\",\"concentration_CFU_per_L\"]].head(8))\n",
    "\n",
    "# ---------- Aggregate per borehole ----------\n",
    "agg = (\n",
    "    links\n",
    "    .groupby([\"borehole_id\", \"borehole_type\"], as_index=False)\n",
    "    .agg(\n",
    "        total_surviving_fio_load=(\"surviving_fio_load\", \"sum\"),\n",
    "        Q_L_per_day=(\"Q_L_per_day\", \"first\"),  # same Q per borehole\n",
    "    )\n",
    ")\n",
    "agg[\"concentration_CFU_per_L\"] = agg[\"total_surviving_fio_load\"] / agg[\"Q_L_per_day\"]\n",
    "\n",
    "agg.to_csv(bh_out, index=False)\n",
    "print(f\"✅ Wrote borehole-level concentrations: {bh_out}\")\n",
    "print(agg.head(8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
